\chapter{Ambiente de Análise}
\label{chap:framework}

Inicialmente, no capítulo anterior, foi feito um levantamento dos
aspectos envolvidos no projeto do \acs{nilm}, levando em consideração
diversos os pontos técnicos para a aplicação do \acs{nilm} em um programa
de \acs{ee}. Em seguida, foi apresentado a evolução do projeto dessa
tecnologia no \acs{cepel}.  Observou-se a necessidade de detecção de
eventos de transitório para a operação do \acs{nilm} quando o mesmo
explora a informação presente na alteração de um estado operativo de
um equipamento. Essa etapa recebeu atenção do \acs{cepel} atualmente,
onde se decidiu aplicar um filtro de derivada de Gaussiana,
metodologia explicada em maiores detalhes na
Seção~\ref{ssec:met_cepel}. Aqui apenas será recapitulado que além da
aplicação de um limiar na resposta do filtro, há a remoção de
candidatos ruidosos e de candidatos próximos.

O trabalho atual firmou-se com o intuito de sistematizar o processo de
ajuste de parâmetros da metodologia proposta pelo \acs{cepel} e
estudar o comportamento da metodologia em uma nova base de dados que
contém a presença de ruídos causados pela dinâmica de carga
de equipamentos alguns aparelhos operando na rede --- os equipamentos
\acs{c5} (ver definições na Subseção~\ref{ssec:modelos_carga}). 
Além disso, ao observar nos capítulos anteriores a complexidade do
projeto, percebeu-se a necessidade da implementação de uma
infraestrutura que permitisse unificar o projeto e facilitar o seu
desenvolvimento. Este capítulo se dedica à descrição dessa
infraestrutura --- o ambiente de análise. As necessidades para sua
implementação serão debatidas mais profundamente na
Seção~\ref{sec:motivacao_framework}. As seções seguintes
(\ref{sec:daq_info}--\ref{sec:otimizacao}) irão detalhar os módulos do
ambiente implementado. Houve diversas alterações na versão original,
trazendo benefícios operacionais e melhor capacidade de compreensão e
interação com os dados e análises, especialmente no aspecto gráfico.
Além disso, foram adicionados duas maneiras de remoção de eventos
(Subseção~\ref{ssec:evento}) e a construção do gabarito
(Seção~\ref{sec:gui}) --- estimativa da informação desagregada a ser
obtida --- que aqui são resumidos:

\begin{itemize}
\item Remoção de eventos próximos utilizando a média dos candidatos:
os candidatos dentro de uma janela deslizante são substituídos pelo valor
de sua média;
\item Remoção de eventos inconsistentes: remoção do evento caso os
sinais de entre a resposta do filtro e da variável \acs{di} sejam
opostos;
\item Construção do gabarito: a informação que se deseja obter é o
consumo desagregado de energia por equipamento, porém conseguir essa 
informação para o ajuste das técnicas não é simples, sendo necessário
realizar submedição em cada equipamento e anotar os instantes das
mudanças de estados de operação de cada equipamento. Em alguns casos
--- como os dados coletados pelo \acs{cepel} (descritos no próximo
capítulo) ---, apenas a segunda informação está disponível, de forma
que é necessário estimar o consumo desagregado dos equipamentos a ser
obtido nos arquivos. Para melhorar a estimativa de consumo a ser
obtida, contida no arquivo chamado de gabarito, possibilitou-se a
interação gráfica para a construção dessa estimativa.
\end{itemize}

A Seção~\ref{sec:otimizacao} apresenta a descrição da versão do
algoritmo genético implementado, uma adaptação de um \gls{es} para
possibilitar maior capacidade computacional às configurações que
melhor se adequam ao problema sendo otimizado. Os detalhes da
aplicação dessa versão adaptada do \gls{es} para o ajuste de
parâmetros será debatido mais adiante, no
Capítulo~\ref{chap:metodologia}.

\section{Da Necessidade}
\label{sec:motivacao_framework}

No capítulo anterior, foram observados diversos aspectos envolvidos
para o desenvolvimento da tecnologia do \gls{nilm} e a configuração do
projeto no \gls{cepel}. Com base nisso, as seguintes dificuldades
podem ser destacadas:

\begin{enumerate}[label={Item} \arabic* - ,ref=\arabic*,align=left]
\item\label{itm:dif1} era necessário melhorar a capacidade de
interpretação dos dados e da análise;
\item\label{itm:dif2} o \acs{cepel} pode julgar necessário alterar a
sua abordagem conforme as necessidades do projeto, como as técnicas
aplicadas, frequência de amostragem e o medidor;
\item\label{itm:dif3} a larga gama de técnicas encontradas no
levantamento bibliográfico, e em especial a chamada de atenção para o
fato de sua utilização em paralelo ser benéfica para a capacidade de
desagregação do \gls{nilm}, mostra que o projeto deve ter aptidão de
agregar em um único ambiente tudo aquilo que for desenvolvido, pois
mesmo que uma técnica não seja ótima, sua operação em paralelo pode
ser benéfica para o sistema de desagregação como um todo;
\item\label{itm:dif4} ainda que o item anterior não seja de interesse,
é importante manter todas as abordagens já desenvolvidas em um único
ambiente para garantir uma melhor evolução do projeto;
\item\label{itm:dif5} o levantamento bibliográfico mostrou que há uma
dificuldade dos autores em obter dados onde a informação desagregada
em energia também esteja disponível\footnote{Para fugir dessa
dificuldade, \cite{nilm_liang_pt2_2010_40} chegou a criar um simulador
de Monte-Carlo (ver pp.~\pageref{nilm:multiplas_tecnicas}).}. Tem-se uma
necessidade de tanto obter um meio para armazenar os momentos de
transição dos estados operativos para treinar (se existentes) técnicas
supervisionados, quanto ter o consumo desagregado para avaliar a
eficiência do \gls{nilm}. No exterior disponibilizaram-se dois
conjuntos de dados (ver Subseção~\ref{top:nilm_padrao}) justamente
com o intuito de possibilitar dados para autores e permití-los
compararem suas técnicas. Para obter a informação desagregada, pelo
menos uma das informações seguintes deve estar disponível, no entanto,
as duas se complementam, sendo desejável trabalhar com ambas: as
marcas caracterizando os momentos de alteração de estados;
e informação de consumo temporal dos equipamentos através de submedidores.
Porém, nem sempre é possível obter as duas informações juntamente.
Devido às dificuldades como o fato de não ser fácil monitorar os estados
operativos de alguns equipamentos, por não ter acesso nem controle de seus
ciclos de maneira trivial, bem como, nem sempre ser possível realizar a
submedição de todos equipamentos, estando essa informação parcialmente ou
até mesmo não disponível.
\end{enumerate}

Viu-se a necessidade do
desenvolvimento de um ambiente de análise que atendesse os seguintes
pontos:

\begin{enumerate}
\item Versatilidade: em vista dos itens
\ref{itm:dif2}--\ref{itm:dif4}, o ambiente deve ser capaz de se
adequar às mudanças no projeto conforme elas ocorram, sem que outras
partes do ambiente sejam afetadas. Devido a isso, optou-se por uma
implementação orientada a objeto, mas se limitando a escolha para uma
linguagem de amplo conhecimento no campo da engenharia. Por isso,
optou-se por desenvolver o ambiente no \emph{Matlab}, que
disponibiliza desde sua versão \emph{R2008a} essa capacidade.
Ainda que o \emph{Matlab} e, em especial, sua linguagem orientada a
objeto sofra em relação a sua performance, o ambiente de análise é
\emph{a posteriori} à coleta de dados, sendo aceitável essa
desvantagem. O interesse no ambiente é de explorar a capacidade das
técnicas, antes de implementá-las para operação em tempo real. O ambiente
foi organizado procurando modularizar os componentes, para que, se
fosse necessário o desenvolvimento ou adaptação de código,
simplificasse o processo para que apenas o módulo em questão seja 
atacado;

\item Capacidade de Interpretação dos Dados e Resultados: o tempo
investido neste ponto retorna em capacidade de interpretação, de forma
que o projeto irá ter um melhor andamento. Um dos aspectos para
atingir isso, é através de uma boa visualização \cite{it_depends}, já
que a mesma é um meio bastante efetivo para a comunicação da
informação (aqui se referindo a informação presente nos dados,
análise etc.). No caso, uma visualização dinâmica permite ainda melhor
compreensão das nuances contidas na informação;

\item Otimização dos Parâmetros: também considerando o
Item~\ref{itm:dif1}, seria interessante obter configurações ótimas de
maneira automática, sem a necessidade do usuário ficar alterando
parâmetros empiricamente até obter um valor considerado bom.
Ademais, que o algoritmo seja capaz de realizar isso encontrando uma
das melhores configurações possíveis para os parâmetros (não
necessariamente a melhor);

\item Estimação da Informação a ser Desagregada pelos Algoritmos
(Construção dos Gabaritos): já
quanto ao Item~\ref{itm:dif5}, os dados disponíveis no \acs{cepel} não
foram amostrados com submedição, tendo apenas acesso às marcas de
mudanças de estado operativo e, por isso, é necessário uma maneira para
estimar a informação desagregada contida nos mesmos. Com esse intuito,
aproveitou-se o ponto ``Capacidade de Interpretação dos Dados e
Resultados'', e adicionou-se essa capacidade na
visualização dinâmica oferecida ao usuário. Essa estimativa da
informação desagregada será referida neste trabalho como
\emph{gabarito}.

\end{enumerate}

O resultado foi um ambiente de análise com $\sim$29.000 linhas de
código distribuídas em $\sim$190 arquivos. Um esboço de sua
arquitetura pode ser observado na Figura~\ref{fig:ambiente_analise}.
As palavras em inglês representam as classes mais importantes dos
módulos como referidas no ambiente. Observa-se que o Módulo de
Leitura, Representação e Interação com os Dados
(Seção~\ref{sec:daq_info}) é a base do ambiente, sendo utilizado
para análise e otimização. O Módulo de Análise dos Dados
(Seção~\ref{sec:analise}) é executado pelo Módulo de Otimização dos
Parâmetros (Seção~\ref{sec:otimizacao}), que realiza diversas
análises iterativamente em busca de uma configuração ótima para os
dados alimentados. 

\begin{figure}[h!t]
\centering
\includegraphics[width=\textwidth]
{imagens/ambiente_de_analise.pdf}
\caption{Esboço do ambiente de análise implementado.}
\label{fig:ambiente_analise}
\end{figure}

É importante notar que apesar do esboço mostrar toda a cadeia para a
obter os parâmetros otimizados, essa não é sua única operação. O
usuário irá determinar sua operação, ex.: seja só para realizar uma
análise, obter os resultados e explorar graficamente a sua resposta,
construir um gabarito para um novo conjunto de dados, explorar os
dados a procura de alguma informação etc.

Um detalhe, a implementação foi realizada em inglês por opção do autor
do trabalho com o intuito de que o programa também seja compreensível
no exterior. Nem todas as informações puderam ser traduzidas para
colocá-las no trabalho, nesses casos será realizado a tradução e
referência aos elementos no texto do trabalho.

\section{Leitura, Representação e Interação com os Dados}
\label{sec:daq_info}

O Módulo de Leitura, Representação e Interação com os dados é o mais
complexo em termos de estrutura no ambiente implementado. Ele conta
com os seguintes segmentos:

\begin{itemize}
\item Dados do Medidor (Subseção~\ref{ssec:dados_medidor}):
representação em memória transitória dos dados do medidor. Uma série
de aspectos tiveram de ser tratados neste segmento;
\item Evento de Transitório (Subseção~\ref{ssec:evento}): contém a informação de
eventos de transitório. Essa representação pode ser criada tanto pelo
usuário durante a criação de um gabarito, ou seja, informar um evento
de transitório e suas propriedades a serem encontradas para avaliar a
performance de análise ou otimizar os parâmetros baseando-se nessa
informação, ou quanto pelo Módulo de Análise, que irá gerar essa
informação através de sua metodologia;
\item Equipamentos (Subseção~\ref{ssec:equipamento}): contém a informação
do estado de consumo dos equipamentos, seus consumo temporal estimado bem
como a estimativa de seu consumo total para o conjunto de dados.
Apesar deste trabalho ainda não ter tratado do problema de geração da
informação dos equipamentos (e por isso essa informação só ser gerada
pelo usuário para o gabarito), é interessante em termos de
continuidade do projeto que essa informação já fosse gerada nos
gabaritos, para que eles não precisem ser revisados no futuro,
contando com toda informação necessária para a otimização e avaliação
de performance. Como foi visto na Subseção~\ref{ssec:nilm_eff_calc} e
frisado diversas vezes em tal capítulo, é necessário dar a eficiência
do \gls{nilm} em termos de energia. Outro aspecto importante para a
motivação da criação dessa informação foi da capacidade de compreensão
dos dados, a informação por equipamento é muito mais intuitiva que os
eventos de transitório, constituindo em um nível mais alto informativo
para a compreensão dos dados, bem como facilitando a geração do
gabarito;
\end{itemize}

A seguir, entrar-se-á em mais detalhes para cada um deles.

\subsection{Dados do Medidor}
\label{ssec:dados_medidor}

Para atender as necessidades do projeto, a implementação da interface
para leitura e representação dos dados do medidor abordou os seguintes
tópicos:

\begin{itemize}
\item Transformação dos dados em um formato único: atualmente o
\gls{nilm} utiliza dados de dois medidores diferentes, sendo
necessário representar essa informação de uma única maneira para
atender a questão de Versatilidade. Um efeito colateral decorrente da
transformação foi a compressão dos dados, que estavam em formatos de
texto e ao serem armazenados em formato binário sofreram compressões de
30$\times$ a 40$\times$ dependendo do número de fases;
\item Robustez: a leitura e transformação dos dados para o formato
único deve ser robusta a possíveis erros durante a aquisição de dados,
sendo eles: descontinuidade da amostragem, seja por intervenção humana
ou algum problema no medidor; ou sobrecarga devido ao consumo
excessivo na rede, geralmente causado pelo acionamento de um equipamento
a motor de maior consumo, como o ar condicionado. Para o primeiro
caso, implementou-se um algoritmo capaz de identificar esses momentos,
e no caso da descontinuidade ser pequena (ex. 10~s, determinado pelo
usuário), a informação entre as bordas dos arquivos é completada com
amostras geradas através de um ajuste linear. Essas amostras são
marcadas para identificar que foram criadas e não medidas. Enquanto
para a sobrecarga, é grampeado o valor de consumo máximo para as
variáveis em que isso ocorre, bem como as amostras são marcas para
identificar os momentos em que isso ocorre;
\item Segmentação da memória persistente: alguns dados contém dias de
amostragens, sendo impossível analisar toda essa informação de uma vez
só em memória transitória. Por isso, segmentou-se os dados em diversos
arquivos com um tamanho pré-definido (ex. 1~hora). Anteriormente era
necessário segmentar a informação manualmente. A segmentação
automática foi realizada de maneira transparente durante a leitura da
base de dados, ou seja, a leitura ocorre sem que o usuário precise se
preocupar em como o conjunto de dados está representado e compreendido
no ambiente;
\item Redução da necessidade de leitura de disco: devido a segmentação
em memória, era necessário garantir que informações nas bordas dos
arquivos estivessem disponíveis para os algoritmos de análise sem que
eles tivessem de requisitar a troca da informação mantida em memória
transitória. Para isso, uma quantidade de amostras nas bordas dos
arquivos segmentados é mantida em memória transitória sempre
disponível, evitando que seja necessário uma navegação excessiva entre
a informação segmentada, reduzindo drasticamente a velocidade dos
algoritmos já que a leitura em disco é lenta;
\item Leitura de redes elétricas com até três fases: era necessário
compatibilidade de leitura de dados de redes monofásicas, bifásicas e
trifásicas, representando essa informação de uma maneira universal. Um
dos fatores que influenciou também na compressão dos dados foi armazenar
para as fases com pouca atividade somente os momentos em que havia
consumo;
\item Informação gráfica: representar graficamente a informação contida
nos dados. Essa funcionalidade é utilizada como base pela interface
gráfica para realizar a interação com os dados.
\end{itemize}

Um exemplo de dados trifásicos em uma residência
\emph{real}\footnote{A palavra real é empregada para identificar
amostragens não geradas em condições de laboratório.} está
disponível na Figura~\ref{fig:casa_real}. As três primeiras subfiguras
são a injeção de corrente (medido em valor eficaz) no sistema,
enquanto a última figura é o fluxo em potência trifásico para as
variáveis descritas na pp.~\pageref{eq:ipqds}. O fluxo de potência é
informado para o consumo trifásico porque o medidor \emph{Yokogawa}
utilizado nessa coleta de dados só permite o acesso a essa informação,
sendo necessário operar com um nível mais agregado de consumo que a
corrente. As barras verticais cinzas indicam como está realizada a
segmentação dos dados em disco. Apesar de não se utilizar esse
conjunto de dados para análise --- nesses dados não há como construir
o gabarito, não sendo possível a otimização dos valores, nem calcular
sua eficiência ---, ele revela uma série de aspectos importantes para
a compreensão do problema envolvido na desagregação do \gls{nilm}, bem
como algumas necessidades durante a implementação da parte de
representação dos dados no ambiente de análise. 

%\begin{landscape}
%\begin{figure}[h!p]
\begin{sidewaysfigure}[p]
\centering
\includegraphics[width=\textwidth]{imagens/RealHouse.pdf}
\caption[Informação gráfica para o interação com dados do medidor]
{Informação gráfica para a interação com os dados do medidor. Gráfico
gerado através do ambiente de análise para um conjunto de dados com
amostragem em 60~\acs{hz} de uma rede trifásica em uma casa
\emph{real} durante aproximadamente um dia de coleta. A injeção de
corrente para cada uma das três fases encontra-se nas subfiguras
superiores, enquanto o fluxo trifásico de potência entrando na rede
elétrica é representado na subfigura inferior. São utilizados as cores
azul, vermelho, verde e preto para as potências ativa, reativa,
harmônica e aparente, respectivamente.}
\label{fig:casa_real}
\end{sidewaysfigure}
%\end{figure}
%\end{landscape}

Quanto a questão da descontinuidade, há uma falha na medição próximo
às 07:15~h do dia~31, mostrando que o algoritmo foi capaz de perceber
essa falha e montar a descontinuidade. Já próximo às 19:20~h, ocorreu
uma outra descontinuidade menor, de 30~s, onde o algoritmo identificou
e uniu as bordas através de um ajuste linear para simular a
continuidade e recuperar a informação perdida. Enquanto isso, o ajuste para a
descontinuidade às 07:15~h não pode ser feito porque houve alterações
de estados operativos dos equipamentos\footnote{Estimar essas
alterações sem nenhuma informação é mais complexo do que a tarefa do
próprio \acs{nilm}, que realiza isso tendo a informação agregada de
consumo.}. Por isso, esse conjunto de dados seria analisado em duas
partes, uma partindo do início até às 07:15~h, e outra do fim da
descontinuidade até o fim da medição.

Também há nesse período a ocorrência de sobrecarga do medidor próximo
às 21:50 do dia 30 (provavelmente causada por um ar condicionado, ver
Figura~\ref{fig:sobrecarga}), onde o algoritmo foi capaz de
identificá-la e alterar os valores dessa amostras para a capacidade
máxima de medição.

Outras condições que se referiu no Capítulo~\ref{cap:nilm} também
podem ser observadas e melhores compreendidas nesse conjunto de dados.
Por exemplo, é possível observar na fase~A
Figura~\ref{fig:c5_ruido}\footnote{Foi necessário reduzir a qualidade
da Figura~\ref{fig:c5_ruido} para permitir a navegação na versão
digital deste trabalho, a figura vetorizada exigia grande capacidade
computacional.}
há a ocorrência de uma \gls{c5} a partir das
20:00~h injetando ruído na rede elétrica devido a sua dinâmica
(provavelmente esse equipamento é uma televisão). Já um exemplo típico de dinâmica causada
pela máquina de lavar roupa se encontra na
Figura~\ref{fig:maquina_lavar}. Apenas como curiosidade, também é
possível observar no período de menor atividade da rede ---
08:00~h--18:00~h do dia 31 --- nitidamente a operação da geladeira (ou
outro equipamento similar) na fase~B.

\begin{figure*}[p!]
  \begin{center}
    \begin{subfigure}[c]{\textwidth}
      \includegraphics[width=\textwidth,height=0.26\textheight]{imagens/RealHouse_ZoomSobrecarga.pdf}
      \caption{Sobrecarga do medidor causado por um equipamento na
        fase A.}
      \label{fig:sobrecarga}
    \end{subfigure}
    \hfill
    \begin{subfigure}[c]{\textwidth}
      \includegraphics[width=\textwidth,height=0.26\textheight]{imagens/RealHouse_maquina_lavar.eps}
      \caption{Um dos estados operativos da máquina de lavar
        roupa.}
      \label{fig:maquina_lavar}
    \end{subfigure}
    \hfill
    \begin{subfigure}[c]{\textwidth}
      \includegraphics[width=\textwidth,height=0.26\textheight]{imagens/RealHouse_aparelho_c5.jpg}
      \caption{Dinâmica de uma carga C5 na fase~A. Observe a diferença
entre a relação de sinal ruído dessa fase em relação com a fase~B.}
      \label{fig:c5_ruido}
    \end{subfigure}
  \end{center}
\caption[Alguns exemplos de dificuldades encontrados nos dados reais]{
Alguns exemplos de dificuldades encontrados nos dados reais da
Figura~\ref{fig:casa_real}.}
\label{fig:dificuldades}
\end{figure*}

%\begin{figure*}[ht!]
%  \ContinuedFloat
%    \begin{subfigure}[c]{\textwidth}
%      \label{fig:maquina_lavar}
%      \caption{Um dos estados operativos da máquina de lavar
%        roupa.}
%      \includegraphics[width=\textwidth,height=0.26\textheight]{imagens/RealHouse_maquina_lavar.eps}
%    \end{subfigure}
%
%  \caption{Casos destacados no conjunto de dados da Figura~\ref{fig:casa_real}.}
%\end{figure*}
%\FloatBarrier


\subsection{Evento de Transitório}
\label{ssec:evento}

Eventos são gerados tanto pelo usuário quando criando o gabarito ou
quanto pelo algoritmo de análise. A informação nos eventos de
transitório são de mais baixo nível àquelas contidas no objeto que
representa o equipamento. Suas capacidades são: 

\begin{itemize}
\item \acs{fex} para classificação: Realiza o cálculo das variáveis
\acs{di}, \acs{dp}, \acs{dq}, \acs{dd} e \acs{ds} e extrai uma janela
da envoltória dessas variáveis durante o transitório;
\item Remoção de eventos ruidosos: se \acs{di}, \acs{dp} ou \acs{ds}
forem menores a um limiar, o evento é considerado como ruidoso. O
corte pode ser realizado em apenas uma dessas variáveis, no momento o
corte é apenas em \acs{di}.
\item \textlabel{Remoção de eventos próximos pelo valor da média
dentro de uma janela deslizante}{text:media}: Para a
remoção de eventos próximos, adicionou-se uma outra maneira de realizar
a mesma. Ao invés de simplesmente ignorar a informação de outros
candidatos dentro de uma janela após um número determinado de
amostras, como realizado na metodologia proposta pelo \acs{cepel},
decidiu-se avaliar uma nova maneira de realizar essa tarefa,
empregando a média dos valores das amostras desses
candidatos. A inspiração para isso se deu pelo fato da maioria dos
eventos próximos removidos serem causados por um acionamento de
equipamento com um pico de consumo, assim, ao substituir o evento
causada pelo acréscimo de consumo e seu decréscimo logo em seguida por
sua média, obtém-se um evento mais próximo ao centro do distúrbio
causado pelo equipamento na rede. Um exemplo pode ser observado na
Figura~\ref{fig:analise_eventos}; 
\item \textlabel{Remoção de eventos
inconsistentes}{text:incosistentes}: ao observar que grande parte dos
eventos que eram removidos por serem eventos próximos na verdade eram
causados por eventos criados após um pico de consumo devido ao
acionamento de um equipamento, que gerava um evento na decréscimo de
consumo após o pico, decidiu-se adicionar um novo tipo de corte. Esse
corte remove os candidatos que tiverem o sinal da resposta do filtro
de derivada de Gaussiana invertido em relação ao degrau de consumo
causado pelo evento. Para esses eventos citados, a resposta do filtro
é negativa, enquanto o degrau é positivo, havendo assim inconsistência
entre os dois;
\item \textlabel{Estado dos eventos}{text:estados_eventos}: para
melhorar a capacidade de análise, eventos removidos não são excluídos,
tendo apenas seus estados alterados. Os possíveis estados dos eventos
são:
\begin{itemize}
\item Em bom estado;
\item Removido devido a evento próximo, nesse caso indicando qual
evento que causou sua remoção;
\item Evento ruidoso;
\item Inconsistente (ver item anterior);
\item Quantidade de amostras insuficientes, se não houver amostras
suficientes para construir o evento;
\item Ainda não preenchido, quando o evento é criado mas ainda é
necessário preencher a \gls{fex} e realizar os cortes para determinar
o seu estado.
\end{itemize}
\item Mudança de estado e equipamento: os eventos também armazenam a
informação de qual equipamento pertencem e qual foi a mudança de estado
por eles representadas. Por enquanto essa informação só é preenchida
pelo usuário durante a criação do gabarito;
\item Informação gráfica: os eventos são representados conforme o seu
estado (observar exemplos na Figura~\ref{fig:analise_eventos}).
São utilizadas linhas verdes verticais para indicar eventos de
transitório onde houve acréscimo no consumo, e linhas vermelhas para
decréscimo.  Eventos removidos possuem linhas cinza tracejadas.
Dependendo de como a geração gráfica é realizada, será criado uma área
cinza para a região onde será realizada a extração da envoltória e
duas faixas amarelas indicando as amostras para as quais será
calculado o valor pré/pós-transitório utilizados para calcular o
degrau, como indicado nas equações
\ref{eq:deltasMacro}.
\end{itemize}


\subsection{Equipamentos}
\label{ssec:equipamento}

A informação contida no equipamento une toda aquela contida nos eventos.
Nela, reconstrói-se todos os estados operativos do equipamento
temporalmente e seus consumos. No momento, essa informação só é gerada
pelo usuário quando preenchendo a informação do gabarito. Para ter uma
ideia de como o processo é realizado observe a
Figura~\ref{fig:gui_informacao}. As capacidades desse elemento são:

\begin{itemize}
\item Detecção automática de estados: quando gerando o gabarito,
faz-se uma análise de dendrograma para agregar os eventos de
transitório com informações de \acs{di}, \acs{dp}, \acs{dq}, \acs{ds}
próximas. O usuário só necessita alterar o nome dos estados pré/pós
transitório dos eventos agrupados, simplificando o processo de geração
do gabarito;
\item Informação gráfica: a capacidade de geração de informação dos
equipamentos é bem mais extensa que a dos eventos. Para evitar
redundância de informação, refere-se diretamente as figuras onde são
mostradas as características dos dados que foram gerados através do
método de informação gráfica de cada equipamento. Estes são os possíveis 
gráficos de serem gerados são:
\begin{itemize}
\item gráfico do consumo temporal por equipamento para os dados,
Figura~\ref{fig:temporizado_app_time}. Esse gráfico representa a
energia desagregada estimada a ser encontrada;
\item gráfico circular de consumo dos equipamentos,
Figura~\ref{fig:temporizado_app_pie};
\item gráfico das envoltórias para todos os eventos de transitório,
Figura~\ref{fig:temporizado_geladeira}. Essa informação auxilia a
encontrar eventos anômalos, como o evento destacado na
Figura~\ref{fig:temporizado_ventilador}.
\end{itemize}
\end{itemize}

\section{Interação Gráfica com o Usuário}
\label{sec:gui}

A interação gráfica com o usuário oferece uma melhor compreensão dos
dados. Além disso, este módulo também permite a capacidade de geração
do gabarito onde está toda informação considerada como alvo para o
\gls{nilm}, desde os momentos onde ocorreu os transitórios, até a
estimativa de informação de energia. Por enquanto o módulo só opera
com a informação dos dados do medidor, contudo sua expansão para
realizar a interação com a informação de análise não é complexa e
se pretende realizar sua implementação no futuro. A seguir estão
suas capacidades:

\begin{sidewaysfigure}[p]
\centering
\includegraphics[width=\textwidth]{imagens/Temporizado_gui_evento_sobreposto.png}
\caption[Informação gráfica para o Módulo de Interação Gráfica com os
Dados: Evento de Transitório com Sobreposição.]{Informação gráfica
para o Módulo de Interação Gráfica com os Dados: Evento de Transitório com
Sobreposição. A região com as amostras para o cálculo da média de pós
transitório está sobrepondo com outro evento.}
\label{fig:gui_evento_sobreposto}
\end{sidewaysfigure}

\begin{sidewaysfigure}[p]
\includegraphics[width=\textwidth]{imagens/Temporizado_gui_evento_sobreposto_consertado.png}
\caption[Informação gráfica para o Módulo de Interação Gráfica com os
Dados: Evento de Transitório Corrigido.]{
Informação gráfica para o Módulo de Interação Gráfica com os
Dados: Evento de Transitório Corrigido. A sobreposição foi corrigida
ao arrastar a região com o ponteiro, o que resulta em uma
estimativa de consumo mais fiel.}
\label{fig:gui_evento_sobreposto_corrigido}
\end{sidewaysfigure}

\begin{itemize}
\item Informação da amostra próxima ao ponteiro: funciona de maneira
muito similar à um medidor, mostrando os valores das amostras \acs{i}
(essa para cada fase), \acs{p}, \acs{q}, \acs{d}, \acs{s} para a
amostra mais próxima ao ponteiro (ver
Figura~\ref{fig:gui_evento_sobreposto}, na região superior à esquerda
denominada de \emph{Cursor Info}, ou informação do ponteiro em
português). Assim, o usuário pode comparar os
valores em cada amostra com facilidade;
\item Geração do gabarito: a dinâmica para a geração do gabarito
ocorre da seguinte maneira: o usuário
seleciona a opção ``Adicionar Evento'' (na figura estando em inglês:
\emph{Add Event}) e então seleciona a amostra que deseja ser o centro
do transitório. Nessa amostra é criado um evento, onde são calculados
os \acs{di}, \acs{dp}, \acs{dq}, \acs{dd}, \acs{ds}. Essa informação é
disponibilizada já calculada para o usuário no canto inferior da
esquerda, contendo tanto o valor do patamar operativo do 
pré/pós-transitório dessas variáveis. O algoritmo
detecta e agrupa os possíveis estados automaticamente por uma análise
em dendrograma. Conforme o usuário vai preenchendo a informação do
gabarito, a interface gráfica mostra-lhe o consumo desagregado por
equipamento e mantém-na atualizada para cada alteração realizada,
possibilitando o usuário saber se o gabarito está sendo preenchido de
maneira correta ou não. Cabe ao usuário determinar o nome do equipamento
e o nome de seus estados. Para equipamentos \acs{c3} a interface gráfica
já os cria automaticamente com o estados \emph{on} (ligado) e
\emph{off} (desligado). É possível selecionar qualquer evento e
alterar suas características, bem como arrastar as regiões aonde são
calculadas as variáveis (ver
Figura~\ref{fig:gui_evento_sobreposto_corrigido}) para corrigir
possíveis sobreposições de eventos ou regiões inicialmente mal
selecionadas.
\item Escolha da informação disponível: há a opção de escolher a
informação disponível na tela (observar
figuras~\ref{fig:temporizado_gui_eventos} e
\ref{fig:temporizado_gui_legenda}),
podendo controlar a disponibilidade gráfica das seguintes informações:
informação de consumo temporal dos equipamentos; centros dos eventos de
transitório (no caso, dos eventos criados pelo usuário no arquivo em
questão); e consumo amostrado pelo medidor. Isso é realizado porque a
junção de toda essa informação de uma só vez acaba criando confusão e
dificuldade para a sua interpretação, assim, com essas opções o
usuário tem controle sobre elas, permitindo que haja comparação das
informações sem que haja sobreposição delas;
\item Armazenar e carregar arquivos: como o gabarito na verdade é uma
estimativa da informação desagregada, é possível gerar diversos
gabaritos para um mesmo conjunto de dados. Por isso, há um mecanismo de
proteção da memória persistente e transitória. Ou seja, enquanto o
usuário altera a informação do gabarito, o mesmo permanece intacto em
disco, assim como se o usuário tentar encerrar a interface gráfica ou
carregar um outro gabarito e houver assincronia entre a informação
na memória persistente e transitória, ele será perguntado se deseja
descartar suas alterações ou sincronizar a informação;
\item Janela de legenda para o consumo dos equipamentos: a informação do
consumo temporal possui uma cor única para cada equipamento, porém
adicionar essa legenda na própria figura com os dados do medidor e
informação do gabarito não era possível sem gerar dificuldade para sua
interpretação, bem como não haveria espaço suficiente para colocar
todos os nomes dos equipamentos (espera-se cerca de 30 a 50 equipamentos nas
residências) na tabela sem comprometer a figura. Por isso, o usuário
tem a opção de abrir uma janela que irá conter essa legenda
(Figura~\ref{fig:temporizado_gui_legenda}), que será atualizada
automaticamente enquanto o usuário preenche o gabarito.
\end{itemize}

\begin{figure*}[p!]
  \begin{center}
    \begin{subfigure}[c]{\textwidth}
      \includegraphics[width=\textwidth]{imagens/Temporizado_gui_eventos.png}
      \caption{Informação disponível ao selecionar amostragem do
medidor e eventos de transitório para o conjunto de dados \emph{Temporizado}.}
      \label{fig:temporizado_gui_eventos}
    \end{subfigure}
    \hfill
    \begin{subfigure}[c]{\textwidth}
      \includegraphics[width=\textwidth]{imagens/Temporizado_gui_legenda.png}
      \caption{Informação disponível ao selecionar a informação
estimada de consumo desagregado por equipamento e a janela de legenda
para o conjunto de dados \emph{Temporizado}.}
      \label{fig:temporizado_gui_legenda}
    \end{subfigure}
  \end{center}
\caption{Informação gráfica para o Módulo de Interação Gráfica com os
Dados: Disposição da informação.}
\label{fig:gui_informacao} \end{figure*}



\section{Análise dos Dados}
\label{sec:analise}

O Módulo de Análise dos Dados foi implementado para refletir o ponto
inicial da metodologia empregada pelo \acs{cepel}, mas adaptando o
mesmo para o ambiente de análise, corrigindo possíveis pequenos
equívocos no código original e expandindo o mesmo. Suas aptidões
são:

\begin{itemize}
\item Continuidade da análise: a versão de ponto de partida gerava
um evento na leitura de cada novo arquivo. Isso ocorria porque o
consumo inicial em cada arquivo raramente é zero, e a inicialização
das condições do filtro pelo \emph{Matlab} é realizada considerando
que ele estava em repouso recebendo entradas nulas e respondendo
valores também nulos. Para dar a continuidade entre as segmentações
dos dados o próprio \emph{Matlab} fornece o vetor de condições finais
$\underline{z}_f$ no final da leitura de um arquivo para ser aplicado
na leitura do próximo arquivo como condições inicias
$\underline{z}_i$. Porém, no caso do conjunto de dados e nas possíveis
reinicializações da análise devido à descontinuidade das amostras, era
necessário determinar como simular a condição onde o filtro estava em
repouso (com respostas nulas em estado permanente) para a entrada com
o valor da amostra inicial. Por exemplo, no caso da
Figura~\ref{fig:casa_real} há uma descontinuidade às 07:15 do dia 31
causada por alguma falha na medição, que, ao executar a convolução do
filtro no período posterior a essa falha, irá gerar um evento de
transitório falso uma vez que haverá sensibilização na resposta do
\acs{fir} pelo motivo referido. 

Seja, assim, a determinação da resposta
$y(m)$ para um \acs{fir} dada por \ref{eq:y_m_fir}
\cite[pp.~311-312]{oppenheim}\footnote{Referência utilizada pelo
\emph{Matlab} na implementação do \acs{fir}.}, onde $b(k)$ é o k-ésimo
coeficiente do filtro de ordem $n-1$. Deseja-se encontrar o
vetor $\underline{z}_i$ que, dado o vetor de amostras de entrada
$\underline{x}$, gerará uma resposta $\underline{y}$ constante e
nula para toda janela do filtro. Ao representar \ref{eq:y_m_fir} em
forma matricial e igualando $\underline{y}=0$, obtém-se
\ref{eq:matrix_fir}. No caso, quer-se simular que o filtro estava em
repouso para a primeira amostra do arquivo, bastando fazer
$\underline{x}=a_1$, onde $a_1$ é a primeira amostra do conjunto de
dados ou a primeira amostra após uma descontinuidade. Assim,
utiliza-se \ref{eq:matrix_fir} com o valor de $a_1$ para todo o vetor 
$\underline{x}$;
\begin{subequations}
\begin{eqnarray}\label{eq:y_m_fir}
y(m) = b(1)x(m)+z_1(m-1)  \nonumber \\
z_1(m) = b(2)x(m)+z_2(m-1)  \nonumber \\
\;\;\vdots\;\;\;\;\;\; =
\;\;\;\;\;\;\;\vdots\;\;\;\;\;+\;\;\;\;\;\;\vdots\;\;\;\;\;\;\;  \\
z_{n-2}(m) = b(n-1)x(m)+z_{n-1}(m-1)  \nonumber \\
z_{n-1}(m) = b(n)x(m) \nonumber
\end{eqnarray}
\begin{equation} \label{eq:matrix_fir}
\underline{z} = 
\underbrace{\begin{bmatrix}
b(n-1) & b(n-2)   & b(n-3) & \dots & b(1) \\
       & b(n-2)   & b(n-3) & \dots & b(1) \\
       &          & b(n-3) & \dots & b(1) \\
       &\mathbf{0}&        & \ddots & \vdots \\
       &          &        &        & b(1) \\
\end{bmatrix}}_{\mathbf{B}'}\underline{x}
\end{equation}
\end{subequations}

\item Pareamento da resposta do \acs{fir} com os dados: como a análise
é \emph{a posteriori}, para facilitar a interpretação, remove-se o
atraso na resposta do \acs{fir} para que a mesma fique alinhada com a
amostra sendo analisada, facilitando a compreensão do problema;

\item Janela do filtro com apenas com valores relevantes: o tamanho da
janela do filtro tem influência direta no tempo de execução do
algoritmo, uma vez que a convolução será realizada com uma janela
maior de pontos para cada uma das amostras analisadas. Diminuir a
janela em duas amostras significa que, para cada amostra no arquivo,
serão realizados pelo menos dois cálculos a menos. Assim, além de dar
um valor limite para o tamanho da janela do filtro, é necessário podar
o mesmo para conter apenas valores relevantes, desconsiderando pontos
com grandeza irrelevante. Para isso, realiza-se um corte para pontos
com ordem de grandeza $10^{-3}$ menores que o ponto de maior
relevância do filtro. Apenas com esse corte já foi possível obter
grandes reduções no tamanho da janela e consequentemente no tempo de
execução do algoritmo;

\item Reconhecimento de múltiplas análises com mesma configuração:
suponha que se deseje realizar quatro análises, duas delas com um filtro com
$\sigma=2$ e valores de corte \acs{di}$_{min}=0,1$ e
\acs{di}$_{min}=0,2$, enquanto os outros dois filtros irão ter 
$\sigma=3$ com os mesmos cortes. Nesse caso, não é necessário gerar a
respostas dos filtros de derivada de Gaussiana quatro vezes, apenas
duas vezes e então aplicar os dois cortes em cada uma dessas
respostas. O ambiente de análise realiza a identificação dessas
ocorrências quando executando múltiplas análises e as executa apenas
uma vez, partilhando essa memória para os algoritmos seguintes; 

\item Informação gráfica: a Figura~\ref{fig:analise_eventos} contém um
exemplo de gráfico gerado para uma análise. É possível observar a
resposta do filtro de derivada de Gaussiana, as regiões
sensibilizadas, os eventos, suas janelas para cálculo das \acs{fex} e
os seus estados (ver pp.~\pageref{text:estados_eventos}) informando se
os mesmos foram aceitos ou foram eliminados devido a algum dos cortes.

\end{itemize}


\begin{sidewaysfigure}[p]
\centering
\includegraphics[width=.8\textwidth]{imagens/Empilhado7_ex_incosistencia_e_media.pdf}
\caption[Exemplo de informação gráfica para o Módulo de Análise dos
Dados.]{Exemplo de informação gráfica para o Módulo de Análise dos
Dados. Na subfigura inferior, as regiões verdes e vermelhas indicam
regiões sensibilizadas por respostas positivas e negativas,
respectivamente. A resposta para o filtro de
derivada de Gaussiana é representado pela linha pontilhada, enquanto a
linha horizontal cinza é o limiar de corte para a geração de uma região
sensibilizada. É possível observar um caso de evento inconsistente e
outro removido devido a evento próximo. Para o caso do evento inconsistente, em azul, seu
degrau de potência é positivo enquanto sua resposta é negativa,
revelando sua inconsistência. Já os eventos próximos representados
pelas caixas amarelas foram removidos por estarem próximos, sendo
substituídos pela sua média (a linha verde). Caso esses eventos não
fossem removidos, eles seriam constituídos de falsos alarmes. Na
subfigura superior é possível observar as regiões que serão utilizadas
para a extração do transitório (região cinza) e as regiões utilizadas
para calcular o degrau de potência (regiões amarelas
pré/pós-transitório). } 
\label{fig:analise_eventos}
\end{sidewaysfigure}


\section{Otimização dos Parâmetros}
\label{sec:otimizacao}

Retornando agora para o esboço do ambiente
(Figura~\ref{fig:ambiente_analise}), observa-se que o Módulo de
Otimização dos Parâmetros utiliza o Módulo de Análise iterativamente
para obter parâmetros ótimos (não necessariamente o ótimo global).
A otimização é feita em posse do gabarito, onde os parâmetros da
análise são alterados pelo otimizador em busca de valores que melhor
adequem a resposta da análise em relação ao gabarito. Os seguintes
tópicos resumem como é realizada a otimização dos parâmetros:

\begin{itemize}

\item Redução de memória transitória: um detalhe operativo, as
análises geradas pelo usuário mantém a informação da resposta do
filtro de Gaussiana após o término da análise pois essa informação é
necessária para gerar a informação gráfica, porém, no caso do
otimizador diversas análises serão geradas, sendo interessante limitar
ao máximo o consumo de memória em cada uma delas. Por isso, as
análises geradas pelo algoritmo remove qualquer informação irrelevante
durante a execução da análise como a resposta do filtro e qualquer
outros elementos não necessários, mantendo apenas os eventos de
transitório;

\item Regras de Pontuação: para realizar a otimização, é necessário
haver uma regra para o otimizador avaliar aquilo que é desejável do
que não é. É natural que essa regra tome como recompensa identificar
corretamente um evento de transitório e como punição gerar um evento
de transitório aonde essa informação não existe. O primeiro caso é
referido de detecção, enquanto o segundo consiste de um falso positivo
ou falso alarme. Também é possível adicionar outras punições, por
exemplo, não é desejável que sejam gerados muito candidatos para serem
removidos, isso irá reduzir a velocidade de processamento e se uma
solução consegue realizar a detecção com acurácia parecida mas gerando
menos candidatos, é preferível optar por essa opção, mesmo que ela
tenha uma performance ligeiramente reduzida para obter uma performance
de execução quando aplicando o algoritmo em um \gls{nilm} operando em
tempo real. Porém, essa punição deve ser pequena, por não ser a
grande questão a ser otimizada. A regra de pontuação utilizada está
representada em \ref{eq:regra_pontuacao}. Ainda, os eventos detectados
pelo Módulo de Análise não estarão exatamente na mesma posição que os
eventos gerados pelo usuário no gabarito, já que o usuário não
necessariamente irá marcar a amostra que constitui o ponto de inflexão da
resposta do filtro e, mesmo que isso ocorra, os eventos podem sofrer
deslocamento quando empregando a remoção de eventos próximos por sua
média. Assim, é preciso definir uma janela de um número máximo de
amostras \acs{jmax} para os quais se aceitará o evento de detecção. O
casamento do evento da resposta da análise com o do gabarito é feito
quando os dois se encontram no máximo à \acs{jmax} amostras de
distância. Caso existam mais de um evento dentro dessa janela, o
casamento é realizado com o evento mais próximo;
\begin{equation}\label{eq:regra_pontuacao}
\textbf{Aptidão}=\gamma_{det}N_{det}+\gamma_{fa}N_{fa}+\gamma_{rem}N_{rem}
\end{equation}
\noindent onde:
\begin{description}
\item[$\text{Aptidão}$] mede a capacidade de resposta da análise realizada,
sendo de interesse maximizar esse valor.
\item[$\gamma_{det}$] é a pontuação que a análise recebe para cada
evento de detecção;
\item[$N_{det}$] é a quantidade de eventos detectados;
\item[$\gamma_{fa}$] é a pontuação que a análise recebe para cada
ocorrência de falso alarme;
\item[$N_{fa}$] é a quantidade de ocorrências de falso alarme;
\item[$\gamma_{rem}$] é a pontuação que a análise recebe para cada
ocorrência de candidatos removidos;
\item[$N_{rem}$] é a quantidade de candidatos removidos.
\end{description}

\item Comparação da resposta da análise com o gabarito: em posse da
regra de pontuação \ref{eq:regra_pontuacao} e a \gls{jmax}, realiza-se a
comparação entre as duas informações e retorna-se a eficiência em termos
de Aptidão. Como dito no item anterior, \gls{jmax} é necessário para
casar os eventos de transitório da resposta do filtro com aqueles
presentes no gabarito;

\item Escolha do algoritmo: a função a ser otimizada não é
diferenciável e portanto não é possível utilizar os métodos
convencionais de otimização. É necessário empregar algum método de
tentativa e erro para realizar essa tarefa. Neste trabalho, optou-se
pela utilização de um \acs{es}, porém outras estratégias de
otimização podem ser utilizadas, como Inteligência de Enxame. 
Aprofundar-se-á nas características do algoritmo
implementado na Subseção~\ref{ssec:es};

\item Capacidade de recuperação do processo caso ocorra alguma falha: 
como as otimizações podem levar dias para serem executadas, viu-se a
necessidade de armazenar informações relevantes do processo enquanto
ele evolui, para garantir que se ocorresse algum problema na máquina
em execução, não houvesse de recomeçar o processo desde a primeira
geração. Assim, a versão do algoritmo é capaz de armazenar, se o
usuário requirir, a evolução do processo de otimização e retornar caso
o processo seja interrompido --- por exemplo, devido à falta de
energia. 

\end{itemize}


\subsection[Algoritmo Genético de Estratégia Evolutiva]{\acf{es}}
\label{ssec:es}

Foi realizada a implementação de uma versão própria de um \acs{es} com
base em \cite[cap. 4]{eiben2003introduction}, mas antes de entrar em
detalhes sobre a versão implementada cabe introduzir o tema sobre
algoritmos de estratégia evolutiva.

\begin{figure}[h!t]
\centering
\includegraphics[width=.9\textwidth]
{imagens/ga.pdf}
\caption[Esboço de um algoritmo evolutivo genérico.]
{Esboço de um algoritmo evolutivo genérico. Baseado em
\cite[pp. 17]{eiben2003introduction}.}
\label{fig:esboco_ga}
\end{figure}

Dispõe-se na Figura~\ref{fig:esboco_ga} a sequência de otimização de
um algoritmo evolutivo genérico. Ela conta com uma população inicial,
onde se recomenda que a mesma seja iniciada aleatoriamente.  Essa
população inicial passará por um processo de seleção parental aonde
serão obtidos os espécimes ou indivíduos para compor a \gls{mu},
população que irá realizar a propagação de sua informação genética
para a \gls{lambda}. Porém, a \acl{lambda} recebe o material
perturbado através de operações de recombinação e mutação. A mutação é
uma pertubação que ocorre somente levando em conta o material de um
único pai, enquanto a recombinação ocorre no mínimo com dois pais. A
capacidade de encontrar novas regiões promissoras (genes alelos) ---
descoberta --- no espaço de busca de soluções e, com isso, adquirir
informação no problema é dada pela mutação através de pertubações
aleatórias. Já a recombinação realiza a otimização dentro de uma área
promissora (no caso, dentro da informação genética dos pais) ---
exploração ---, dando grandes pulos para uma região dentro de duas
áreas. O resultado do material genético perturbado constitui da base
para a geração da prole. Irá ocorrer, então, a seleção dos
sobreviventes, que pode levar em consideração a prole e os pais nesse
processo ($\mu$+$\lambda$) ou apenas a prole ($\mu$,$\lambda$). Os
indivíduos selecionados são a nova geração da população, e o ciclo de
será repetido gerando novas populações até o processo atender uma
condição de parada. Geralmente essa é através de um número máximo de
gerações.

Cabe ainda definir a diferença entre genótipo e fenótipo do ponto de
vista computacional. A representação em genótipo é aquela que sofre as
pertubações e codifica a representação do espécime, enquanto o
fenótipo representa a informação como é demonstrada pelo espécime para
o problema em questão, ou seja, o espaço de solução. Pode haver
diferença entre as duas representações ou não, por exemplo, a
representação \{Norte,Leste,Sul,Oeste\} seria as possíveis
representações do fenótipo, e sua codificação em genótipo poderia ser
feita em \{1,2,3,4\}. Nota-se a importância de não
só saber representar a informação em genótipo para realizar as
operações de pertubação no material, como possuir uma maneira de
decodificá-la novamente no espaço do fenótipo. Para isso, cada solução
do fenótipo deve ser mapeável, bem como cada genótipo tenha a sua
decodificação em apenas uma solução. Ainda, a escolha da representação
irá afetar o problema: no exemplo citado a representação escolhida
não parece ter o significado do fenótipo, uma vez que Norte e Oeste são
vizinhos entre si, enquanto na representação eles estão distantes de três
unidades. Uma escolha em variáveis cíclicas parece representar o
problema fidedignamente
$\{(\text{sen}(\frac{1\pi}{2}),\cos(\frac{1\pi}{2})),
(\text{sen}(\frac{2\pi}{2}),\cos(\frac{2\pi}{2})),
(\text{sen}(\frac{3\pi}{2}),\cos(\frac{3\pi}{2})),
(\text{sen}(\frac{4\pi}{2}),\cos(\frac{4\pi}{2}))\}$, porém, nesse
caso, o genótipo seria representado em duas variáveis.

\subsubsection{Versão original}

O \acs{es} é um algoritmo genético cuja especialidade é a
autoadaptação de sua estratégia evolutiva. O \acs{es} concentra sua
capacidade evolutiva na mutação, enquanto outros algoritmos genéticos
costumam focar na recombinação. Todos os indivíduos passam por
pertubações Gaussianas em seu material genético, no entanto, a ordem
dessas pertubações são ajustadas conforme a evolução da espécie,
aumentando ou diminuindo sua ordem de acordo com as necessidades de
evolução. Assim, o \acs{es} irá aumentar a ordem de suas pertubações
quando distante de um valor ótimo --- sujeito a capacidade de perceber
uma tendência no espaço de solução apontando na direção de um ótimo
--- e reduzir as pertubações conforme se aproxima desse valor para
realizar o ajuste fino. Há também uma pequena taxa de recombinação
para aumentar a velocidade de convergência, normalmente na faixa de
10\%\footnote{As taxas de recombinação e mutação são dadas em termos
de probabilidade de ocorrência.}. A seleção parental não é influenciada pela aptidão
dos indivíduos, quando utilizando taxa de recombinação a escolha dos
pais para haver troca de material genético é realizado de maneira
aleatória uniforme. A melhoria gradual das gerações é realizado pela
seleção dos sobreviventes, que é realizada através de
($\mu$,$\lambda$) com pressão alta de seleção, aonde apenas os
indivíduos mais aptos permanecem para a próxima geração. Entende-se como pressão
de seleção dos sobreviventes a grandeza descrita por
\ref{eq:pressao_selecao}. É importante a seleção
através de ($\mu$,$\lambda$) em comparação com a ($\mu$+$\lambda$)
para evitar ótimos locais, bem como garantir que não haverá propagação
de indivíduos com estratégias mal-adaptadas através das gerações. O
mesmo se dá para versões que utilizam elitismo --- manter ao menos uma
cópia do membro mais apto da população na próxima geração ---, não
sendo recomendado no \acs{es} pelo mesmo problema da seleção parental
através de ($\mu$+$\lambda$). É importante também que a seleção de
sobreviventes aplique uma alta pressão de seleção, garantindo a
capacidade adaptativa do \acs{es}, normalmente utilizando
$\frac{\lambda}{\mu}=7$.

\begin{equation}\label{eq:pressao_selecao}
\text{Pressão de Seleção} = \dfrac{\lambda}{\mu}
\end{equation}

Optou-se pela mutação descorrelacionada com $n$ tamanhos de passo
\cite[pp. 76--78]{eiben2003introduction}. Nessa configuração, cada
variável representado no genótipo tem sua própria pertubação, sendo
descrita por \ref{eq:s_esbegin}, enquanto sua pertubação é adaptada
anteriormente de acordo com \ref{eq:sigma_esbegin}. A taxa de
aprendizado é divida em dois parâmetros, $\tau$ e $\tau'$, onde aquele
é a base de aprendizado, que garante uma mudança global na
mutabilidade para preservar os graus de liberdade do problema, e este
é uma mutação específica por coordenada, fornecendo flexibilidade para
empregar diversas estratégias de mutação em diferentes direções. Os
valores indicados para ambos são $1/\sqrt{2n}$ e $1/\sqrt{2\sqrt{n}}$,
respectivamente. O alcance da pertubação no material genético, dado uma
determinada probabilidade de ocorrência fixa, formam elipsoides no
espaço de solução alinhadas com os eixos da representação escolhida. 

\begin{subequations}
\begin{equation}\label{eq:s_esbegin}
x_i' = x_i\sigma_i'N_i(0,1)
\end{equation}
\begin{equation}\label{eq:sigma_esbegin}
\sigma_i' = \sigma_ie^{\tau'N(0,1)+\tau N_i(0,1)}
\end{equation}
\end{subequations}

\noindent onde: 

\begin{description}
\item[$N(0,1)$] e $N_i(0,1)$ são uma pertubação Gaussiana com média
zero e $\sigma$ unitário, a primeira sendo um único valor para todas
as representações, enquanto a segunda uma para cada representação $i$; 
\item[$x_i$] e $x_i'$ é a i-ésima representação e a mesma após sofrer a
pertubação;
\item[$\sigma_i$] e $\sigma_i'$ é a i-ésima estratégia evolutiva e a
mesma após sofrer a pertubação.
\end{description}

Para a recombinação, implementou-se a versão local da mesma por ela
ser mais simples de elaborar, pretendendo alterar no futuro para
a recombinação global que é mais indicada para o caso do \acs{es}.
Porém, a recombinação utilizada não é o quesito principal do
algoritmo, servindo apenas para melhorar a velocidade de convergência.
No caso implementado, o material genético é mesclado entre apenas
dois indivíduos. A informação genética que representa o espaço de
solução é misturada através de \ref{eq:rec_discreta} --- recombinação discreta
---, enquanto a versão para a estratégia evolutiva é realizada através
de \ref{eq:rec_intermediaria} --- recombinação intermediária.

\begin{subequations}
\begin{equation}\label{eq:rec_discreta}
\left\{\begin{array}{l}
x_{i,1}' = x_{i,1} \;\; \textit{ou} \;\; x_{i,2} \;\;\;\;\;\; \text{escolhidos
aleatoriamente}\\
x_{i,2}' = x_{i,\text{o.c.}}
\end{array}\right.
\end{equation}
\begin{equation}\label{eq:rec_intermediaria}
\left\{\begin{array}{l}
\sigma_{i,1}' = \dfrac{(\sigma_{i,1}+\sigma_{i,2})}{2} \\
\sigma_{i,2}' = \dfrac{(\sigma_{i,1}+\sigma_{i,2})}{2}
\end{array}\right.
\end{equation}
\end{subequations}

\noindent onde:

\begin{description}
\item[$x_{i,1}$] e $x_{i,2}$ são a i-ésima representação para o
primeiro e segundo pai, respectivamente; 
\item[$x_{i,o.c.}$] é a i-ésima representação para o pai não
selecionado para $x_{i,1}'$;
\item[$\sigma_{i,1}$] e $\sigma_{i,2}$ são a i-ésima estratégia
evolutiva para o primeiro e segundo pai, respectivamente;
\item[$x_{i,1}'$] e $x_{i,2}'$ são a i-ésima representação para o
primeiro e segundo pai após a pertubação, respectivamente; 
\item[$\sigma_{i,1}'$] e $\sigma_{i,2}'$ são a i-ésima estratégia
evolutiva para o primeiro e segundo pai após a pertubação,
respectivamente.
\end{description}

\begin{figure}[h!t]
\centering
\includegraphics[width=.9\textwidth]{imagens/Ackley.png}
\caption{Função de \emph{Ackley} em duas dimensões para $-30,0< x_i <
30,0$.}
\label{fig:funcao_ackley}
\end{figure}

A referência \cite[pp. 84]{eiben2003introduction} cita um exemplo de um
outro autor que aplicou o \acs{es} para a função de \emph{Ackley},
onde foi utilizado \acs{mu} $= 30$, \acs{lambda} $= 200$, $x_i$
inicial entre $-30,0 < x_i < +30,0$ e um total de 200.000 avaliações
da função de aptidão. Para um total de 10 execuções, o exemplo citado obteve a
melhor solução com valor da função de $7,48\times10^{-8}$. A função de
\emph{Ackley} (Figura~\ref{fig:funcao_ackley}) é altamente multimodal,
com um grande número de mínimos locais, mas com apenas um máximo
global $\overline{x}=0$ e seu valor $f(\overline{x})=0,0$. Para
validar o algoritmo implementado, executou-se o \acs{es} para essas
configurações, obtendo uma ocorrência de convergência para mínimo
local com o valor de $1,34$, e todas as outras ocorrências dão uma
aptidão de média de $1,87\times10^{-7}\pm2.56\times10^{-7}$, onde a
melhor solução obtém a aptidão $1,34\times10^{-8}$. A evolução da
execução com melhor convergência está na Figura~\ref{fig:es_standard},
mostrando o valor médio de aptidão na geração da população na
convergência. Apesar do exemplo citado informar que todos os mínimos
encontrados foram os globais, na versão aqui implementada, ocorrem
casos em que não há a convergência para o mínimo global, ainda que em
outras execuções seja possível encontrar todas as 10 minimizações
convergindo para o mínimo global. É importante ter em mente que a
convergência não ocorre necessariamente para o mínimo global, sendo
uma propriedade bem conhecida dos algoritmos genéticos.  De qualquer
forma, os valores obtidos estão próximos da referência e existem
parâmetros não informados como o valor mínimo de pertubação
$\sigma_{min}$ e o valor inicial para as pertubações
$\sigma_{inicial}$ que podem influenciar na resposta.  Apenas como
referência, os valores utilizados para esses casos foram
$\sigma_{min}=1\times10^{-9}$ e $\sigma_{inicial}=1$.



\begin{figure}[h!t]
\centering
\includegraphics[width=\textwidth]{imagens/es_standard.pdf}
\caption[Evolução para o melhor individuo para a validação da versão
original do ES]{Evolução para o melhor individuo para a validação da versão
original do \acs{es}. O objetivo é minimizar a função de
\emph{Ackley}, que pela visão do \acs{es} funciona como maximizar a
função com seus valores opostos. Por isso, os valores mostrados são
negativos.}
\label{fig:es_standard}
\end{figure}

\subsubsection{Versão Multiespécie}
\label{sssec:multiespecie}

Poderia ser utilizada a versão original do \acs{es} para realizar a
otimização dos parâmetros necessários na abordagem do problema. No
entanto, devido à decorrência da dúvida quanto a qual caminho
percorrer para a análise (ordem de remoção de eventos e quais delas
empregar), são necessárias diversas execuções
do algoritmo para otimizar os valores de maneira individual. Ao invés
de executar cada uma delas individualmente, motivado pela ideia de otimização
multiobjetivo \cite[cap. 9]{eiben2003introduction}, decidiu-se utilizar
a ideia de subpopulações --- que serão referidas por espécies, por
poderem ter cromossomos diferentes dependendo da configuração
utilizada ---, mas aplicando a mesma para um outro conceito. No caso,
ao invés de utilizar espécies para otimização de múltiplas funções
objetivo, esse conceito irá ser utilizado para criar uma dinâmica
entre as várias otimizações sendo realizadas no problema.

A ideia da dinâmica é reservar o esforço computacional para aquelas
abordagens que estão mostrando capacidade de resolver o problema com
maior aptidão, revelando-se uma espécie mais adequada para o
\emph{habitat} em que os espécimes estão sendo avaliados. Porém, isso
deve ser realizado sem comprometer a evolução de espécies que, por
algum motivo, sofreram desvantagem durante o processo evolutivo ---
seja por uma inicialização em condições desprivilegiadas, ou por uma
demora maior para ajustar sua estratégia evolutiva. Assim, a proposta
é executar apenas uma otimização para as diferentes maneiras de
tratar o problema, aonde todas as configurações desejadas irão
competir entre si de modo que o algoritmo irá reservar maior
esforço computacional para otimizar mais profundamente aquela que se
melhor adéqua ao espaço de solução, diferente da versão aonde se
executaria para cada espécie, reservando esforço computacional igual
para espécies que não têm se mostrado adequadas para a solução do
problema.

Assim, propuseram-se duas configurações para as competições dos
espécimens:

\begin{itemize}
\item Interespécie: nesse caso há cooperação entre os individuos de
uma mesma espécie. É calculada a aptidão para cada espécie
(\ref{eq:aptidao_especie}) a ser utilizada como parâmetro na
competição das mesmas e determinar a parcela da população global que
elas tem direito. Uma vez determinado o tamanho da população de cada
espécie, seus indivíduos irão competir entre si para determinar os
sobreviventes. É necessário escolher um método para avaliar a aptidão
das espécies e como determinar suas populações através dele;
\item Intraespécie: os espécimes disputam entre si na população global
independente de qual espécie pertencem. Nessa configuração não há
cooperação entre os indivíduos de uma mesma espécie, apenas os
melhores da população global sobrevivem;
\end{itemize}

Para evitar que espécies não tenham a oportunidade de se desenvolverem
antes que sua população seja drasticamente reduzida ou até mesmo
extinta, tratou-se cada um dos casos individualmente. No caso da
seleção interespécie, é necessário escolher uma função que privilegie
espécies mais aptadas, mas que uma diferença de aptidão muito grande
--- que irá ocorrer em especial durante o inicio da evolução devido a
espécies condicionadas em ambientes mais propícios que outras --- não
elimine toda a diversidade das populações antes que elas adequem sua
estratégia evolutiva. Para isso, escolheu-se empiricamente a função
\ref{eq:funcao_interespecie}, para suavizar a pressão aplicada
em espécies menos aptas. A população reservada para uma espécie para a
próxima geração é dada por \ref{eq:mu}. Entretanto, como se utiliza a
função de transformação em inteiro \emph{floor},
ao somar $\mu_i'$ para cada espécie pode acabar resultando em uma
população menor que $\mu$. Assim, distribui-se aleatoriamente os
indivíduos faltantes nas espécies de forma que a soma dos $\mu_i'$
seja o mesmo que $\mu$. 

Para a avaliação da configuração intraespécie, bem como interespécie,
será utilizada a função de \emph{Ackley} contendo 10 espécies. As
espécies têm de 20 a 29 dimensões, sendo rotuladas sequencialmente de
01 a 10. As espécies de menores índices tem uma carga genética mais
simples de ser adaptada através da estratégia evolutiva por possuir
menos parâmetros livres que aquelas com índices maiores, porém todas
espécies tem a mesma capacidade de resolver o problema --- todas podem
obter o mínimo em zero. Ao observar a Figura~\ref{fig:interespecies},
percebe-se que as espécies inferiores tendem a tomar conta da
população nas primeiras gerações confirmando essa hipótese. Por outro
lado, conforme a evolução ocorre, há uma tendência para o equilíbrio,
uma vez que, nesse caso, todas as espécies são capazes de resolver
igualmente bem o problema. Percebe-se que a espécie 05 (marrom) é
aquela que mais sofre durante as gerações iniciais, porém, por volta
da 30$^a$ geração ela alcança o nível de desenvolvimento das outras
espécies, crescendo gradualmente sua população.

\begin{subequations}\label{eq:inter_especie}
\begin{equation} \label{eq:aptidao_especie}
\text{Aptidão}_{(i)} = \sum^{\lambda_i}_{j=1} \text{Aptidão}_{(i,j)}
\end{equation} 
\begin{equation} \label{eq:funcao_interespecie}
f_{inter}(i)=log_2(\text{Aptidão}_{(i)}-min(\text{Aptidão}_{(i)}|\forall i\in \Gamma)+2)
\end{equation} 
\begin{equation} \label{eq:mu}
\mu_i' = floor\left(\dfrac{f_{inter}(i)}{f_{inter,norm}}\right)
\end{equation}
\begin{equation} \label{eq:fnorm}
f_{inter,norm}= \sum_{\forall i\in \Gamma} f_{inter}(i)
\end{equation}
\end{subequations}

\noindent onde:

\begin{description}
\item[$\lambda_i$] é o tamanho da população da prole da i-ésima
espécie;
\item[$\Gamma$] é o espaço contendo todas as espécies;
\item[$\mu_{i}'$] é o tamanho da população dos pais da i-ésima espécia
para a próxima geração.
\end{description}


\begin{figure}[h!t]
\centering
\includegraphics[width=\textwidth]{imagens/es_interspecies.pdf}
\caption[Competição interespécie.]{Competição interespécie. As linhas
contínuas na subfigura superior indicam os indivíduos mais aptos de
cada espécie. As subfiguras inferiores indicam a população para cada
espécie, sendo a mais inferior a população para a prole, e o outro
caso a população dos pais da espécie.% Na
%subfigura superior
%, as linhas contínuas, tracejadas finas e tracejadas
%grossas indicam respectivamente os individuos mais aptos de cada
%espécie, a média de aptidão da população de cada espécie e os
%individuos menos aptos de cada espécie. As subfiguras inferiores
%indicam a população para cada espécie, sendo a mais inferior a
%população para a prole, e o outro caso a população dos pais da
%espécie.}
}
\label{fig:interespecies}
\end{figure}

Um outro mecanismo foi implementado para impedir a extinção de uma
espécie. Ele funciona como um órgão de proteção da diversidade de
espécies, limitando que espécies próximas de entrarem em extinção
tenham sua população reduzida, independente do quão mal esses
indivíduos se adequam ao \emph{habitat} para o qual estão sendo
avaliados.

Isso foi especialmente importante para o caso de competição
intraespécie, onde uma espécie ao encontrar um material genético de
melhor qualidade em comparação com as outras, rapidamente tomava conta
da população global por espalhar esse material entre sua população com
grande velocidade. Na Figura~\ref{fig:intraspecies_nopressure},
observa-se que, se não fosse esse mecanismo, a espécie azul ou amarela
iriam extinguir todas as outras tomando conta da população
global. Fica evidente também que apenas um órgão de proteção da
diversidade de espécies não é suficiente para garantir a evolução das
espécies, é necessário suavizar a competição, de modo que uma espécie
que por algum motivo se tornou mais apta não extermine outras espécies
rapidamente acabando com sua diversidade e não as dê a oportunidade
para evoluir, já que os indivíduos que sobraram possivelmente ainda não
ajustaram sua estratégia evolutiva. A 
Figura~\ref{fig:intraspecies_nopressurecontrol_info} mostra as
pressões de seleção em ordens muito além daquelas que deveriam
ocorrer, obtendo valores na ordem de 20 logo no inicio da evolução
para as espécies que foram iniciadas em condições menos favoráveis,
eliminando toda sua diversidade em poucas gerações. Já as espécies que
conseguiram se desenvolver, observa-se que as mesmas ao conseguirem
uma aptidão melhor que a da outra espécie rapidamente tomam conta da
população global, acontecimentos marcados pelos picos na pressão de
seleção das espécies antes dominantes. Observa-se também que apenas as
espécies mais simples conseguiram evoluir o suficiente para convergir
para o mínimo global.

\begin{figure}[h!t]
\centering
\includegraphics[width=\textwidth]{imagens/es_intraspcies_nopressurecontrol.pdf}
\caption[Competição intraespécies sem intervenção na
competição.]{Competição intraespécies sem intervenção na competição.}
\label{fig:intraspecies_nopressure}
\end{figure}

\begin{figure}[h!t]
\centering
\includegraphics[width=\textwidth]{imagens/es_intraspcies_nopressurecontrol_pressureInfo.pdf}
\caption[Pressão de seleção para competição intraespécie sem
intervenção na competição.]{Pressão de seleção para competição
intraespécie sem intervenção na competição.}
\label{fig:intraspecies_nopressurecontrol_info}
\end{figure}

Em vista disso, implementou-se um mecanismo de controle de pressão de
seleção por espécie. Esse mecanismo aceita um valor máximo de
pressão para cada espécie, se o valor ultrapassar o limiar, então se 
reduz sua pressão ao alocar espaço da população para essa espécie
retirando das espécies com maior alocação de população até que a
alocação de população dessas espécies que ultrapassaram o corte máximo
de pressão resultem em um valor aceitável da mesma. A escolha de
retirada da alocação de indivíduos é feita da seguinte maneira:

\begin{itemize}
\item Inicia-se reduzindo a alocação de população da espécie com maior
população;
\item Caso o valor da espécie de maior população atingir o tamanho da
população de uma outra espécie, adiciona-se essa espécie para a
redução de população e continua o processo. Caso isso ocorra
novamente, a próxima espécie também será adicionada para redução de
população e o processo continua até que seja determinado quais
espécies irão ceder espaço para que a população das espécies com altas
pressões satisfaça o critério mínimo;
\item Quando há o agrupamento de espécies para redução e a
necessidade de reduzir um número não inteiro de população em cada
espécie agrupada, a escolha do resíduo da divisão é feita
aleatoriamente. Ex. se houver de suprir 100 espécimes para garantir que
a pressão de seleção seja feita em níveis aceitáveis, e houver 3
espécies tendo sua população reduzida, retira-se 33 indivíduos de
cada uma delas, porém a escolha da espécie que perderá mais um
individuo será realizada aleatoriamente uniforme.
\end{itemize}

A execução para uma pressão máxima de 7,3 pode ser visualizada na
Figura~\ref{fig:intraspecies_pressurecontrol}, onde fica evidente a
convergência da população para a máxima aptidão (ou mínimo da função
da \emph{Ackley}). Também se observa uma mudança menos brusca quando
comparado à versão sem intervenção na competição, mostrando que o
controle é importante para garantir mudanças mais suaves na
configuração da população. Uma observação importante pode ser
realizada quanto ao órgão de proteção de diversidade de espécies: não
fosse sua operação, diversas espécies teriam sido extintas durante o
processo evolutivo. Na
Figura~\ref{fig:intraspecies_pressurecontrol_info}, observa-se a
pressão de seleção requerida pela competição natural, e aquela
aplicada pelo sistema de intervenção. Em certos casos, a competição
natural chega a exigir pressões de até 500 unidades, o que acabaria
com a diversidade de uma espécie em uma única geração. Assim, ao optar
pela versão de competição intraespécies faz-se necessário interferir
na competição para que todas as espécies tenham chances de evoluir.
Ainda, as espécies de índices mais altos precisam de mais tempo para
chegarem em seu auge. Isso ocorre pela maior dificuldade para o ajuste
da estratégia de evolução devido a maior presença de parâmetros livres
nessas espécies, bem como a menor alocação de população para sua
evolução uma vez que essas espécies irão tender a se inicializar
probabilisticamente com menor aptidão --- a dispersão nas dimensões a
mais tenderão a aumentar o erro e, consequentemente, reduzir a aptidão
dessas espécies.

\begin{figure}[h!t]
\centering
\includegraphics[width=\textwidth]{imagens/es_intraspecies_pressurecontrol.pdf}
\caption[Competição intraespécies com intervenção na
competição.]{Competição intraespécies com intervenção na competição.}
\label{fig:intraspecies_pressurecontrol}
\end{figure}

\begin{figure}[h!t]
\centering
\includegraphics[width=\textwidth]{imagens/es_intraspcies_pressurecontrol_pressureInfo.pdf}
\caption[Pressão de seleção para competição intraespécie com 
intervenção na competição.]{Pressão de seleção para competição
intraespécie com intervenção na competição.}
\label{fig:intraspecies_pressurecontrol_info}
\end{figure}

Há uma nítida diferença entre como as duas seleções se comportam. Ao
comparar as figuras~\ref{fig:interespecies} e
\ref{fig:intraspecies_pressurecontrol}, percebe-se que o caso de
competição interespécie tem uma mudança bastante tênue na configuração
da população, privilegiando as espécies com melhor aptidão
proporcionalmente à sua aptidão como espécie. No caso, a escolha da
função torna a vantagem pequena entre elas, já que se utiliza uma
atenuação logarítmica. Enquanto isso, na competição intraespécie com
intervenção (a versão sem intervenção não é recomendada) observa-se
que o crescimento da população da espécie ocorre gradualmente conforme
seus indivíduos ocupam posições privilegiadas no espaço de
solução. Seria interessante adiar a competição, dando um número de
gerações iniciais para os quais as espécies evoluiriam sem competir,
deixando as mesmas ajustarem sua estratégia evolutiva e estarem
em um estágio pré-evoluido para então começarem a competir entre si.
Comparando essas mesmas figuras novamente, observa-se que o método
de competição intraespécies, com a implementação desse novo mecanismo,
favorece espécies com carga genética mais simples de ser otimizada ou
que começaram em condições mais favoráveis.

